{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pyarrow.parquet as pq\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def perform_pca(df, n_components=2):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    modified_df = df.copy()\n",
    "    modified_df[\"pca_sales\"] = pca.fit_transform(df[[\"0_sales\", \"sales_avg_3_months\", \"sales_avg_6_months\"]])\n",
    "    modified_df[\"pca_views\"] = pca.fit_transform(df[[\"0_PLPViewsPerDay\", \"PLPViewsPerDay_avg_3_months\", \"PLPViewsPerDay_avg_6_months\"]])\n",
    "    modified_df[\"pca_clicks\"] = pca.fit_transform(df[[\"0_PLPClicksPerDay\", \"PLPClicksPerDay_avg_3_months\", \"PLPClicksPerDay_avg_6_months\"]])\n",
    "    modified_df[\"pca_pdp\"] = pca.fit_transform(df[[\"0_PDPCountPerDay\", \"PDPCountPerDay_avg_3_months\", \"PDPCountPerDay_avg_6_months\"]])\n",
    "    modified_df[\"pca_cart\"] = pca.fit_transform(df[[\"0_TotalAddToCartPerDay\", \"TotalAddToCartPerDay_avg_3_months\", \"TotalAddToCartPerDay_avg_6_months\"]])\n",
    "    return modified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_actual_data(of, columns):\n",
    "    train_df = pq.ParquetDataset(f\"~/bhavesh-couture/Downloads/local/{of}/data/train\").read(columns=[\"productid\"] + columns + [\"yQuantity\"]).to_pandas()\n",
    "    test_df = pq.ParquetDataset(f\"~/bhavesh-couture/Downloads/local/{of}/data/test\").read(columns=[\"productid\"] + columns).to_pandas()\n",
    "    actual = pd.read_parquet(\"~/bhavesh-couture/Downloads/local/actualData\").rename(columns={\"actual\": \"yQuantity\"})\n",
    "    return train_df, test_df, actual\n",
    "\n",
    "def train_model_and_predict(x_train, y_train, x_test):\n",
    "    model = sm.OLS(y_train, sm.add_constant(x_train)).fit()\n",
    "    print(model.summary())\n",
    "    y_pred = model.predict(sm.add_constant(x_test))\n",
    "    return y_pred\n",
    "\n",
    "def normalize(df, return_min_max=False):\n",
    "    min_value = df.min()\n",
    "    max_value = df.max()\n",
    "    normalized_df = (df - min_value) / (max_value - min_value)\n",
    "    if return_min_max:\n",
    "        return normalized_df, min_value, max_value\n",
    "    return normalized_df\n",
    "\n",
    "def inverse_normalize(df, min_value, max_value):\n",
    "    return df * (max_value - min_value) + min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse, mean_absolute_percentage_error as mape, r2_score\n",
    "def metrics(actual, predicted):    \n",
    "    y_true = actual\n",
    "    y_pred = predicted\n",
    "    print(f\"rmse: {mse(y_true, y_pred)**(0.5)}\")\n",
    "    print(f\"mape: {mape(y_true, y_pred)}\")\n",
    "    print(f\"r2_score: {r2_score(y_true, y_pred)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca_experiment(of):\n",
    "    attributes = [\"sales\", \"PLPViewsPerDay\", \"PLPClicksPerDay\", \"PDPCountPerDay\", \"TotalAddToCartPerDay\"]\n",
    "    columns = reduce(lambda a,b: a+b, map(lambda attribute: [f\"0_{attribute}\", f\"{attribute}_avg_3_months\", f\"{attribute}_avg_6_months\"], attributes))\n",
    "    print(f'feature: {\", \".join([f\"pca({columns[j]}, {columns[j+1]}, {columns[j+2]})\" for j in range(0, len(columns), 3)])}')\n",
    "    train, test, actual = load_train_test_actual_data(of, columns)\n",
    "    train, test = perform_pca(train, 1), perform_pca(test, 1)\n",
    "    \n",
    "    x_train, y_train = train[[\"pca_sales\", \"pca_views\", \"pca_clicks\", \"pca_pdp\", \"pca_cart\"]].copy(), train[\"yQuantity\"].copy()\n",
    "    x_test = test[[\"pca_sales\", \"pca_views\", \"pca_clicks\", \"pca_pdp\", \"pca_cart\"]].copy()\n",
    "\n",
    "    x_train, x_test = normalize(x_train), normalize(x_test)\n",
    "    y_train, y_min, y_max = normalize(y_train, return_min_max=True)\n",
    "    print(y_min, y_max)\n",
    "\n",
    "    y_pred = train_model_and_predict(x_train, y_train, x_test)\n",
    "    test[\"predictedyQuantity\"] = inverse_normalize(y_pred, y_min, y_max)\n",
    "    test[[\"productid\", \"predictedyQuantity\"]].to_csv(f\"~/bhavesh-couture/Downloads/local/{of}/predictions_pca.csv\", index=False)\n",
    "    return test, actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_n_months_experiment(of, n, attributes):\n",
    "    columns = reduce(lambda a,b: a+b, map(lambda attribute: [f\"{i}_{attribute}\" for i in range(0, n)], attributes))\n",
    "    print(f'features: {\", \".join(columns)}')\n",
    "\n",
    "    train, test, actual = load_train_test_actual_data(of, columns)\n",
    "    x_train, y_train = train[columns].copy(), train[\"yQuantity\"].copy()\n",
    "    x_test = test[columns].copy()\n",
    "\n",
    "    x_train, x_test = normalize(x_train), normalize(x_test)\n",
    "    y_train, y_min, y_max = normalize(y_train, return_min_max=True)\n",
    "    print(y_min, y_max)\n",
    "\n",
    "    y_pred = train_model_and_predict(x_train, y_train, x_test)\n",
    "    test[\"predictedyQuantity\"] = inverse_normalize(y_pred, y_min, y_max)\n",
    "    test[[\"productid\", \"predictedyQuantity\"]].to_csv(f\"~/bhavesh-couture/Downloads/local/{of}/predictions_{n}_months.csv\", index=False)\n",
    "    return test, actual"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA MenShirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, actual = perform_pca_experiment(\"menShirts\")\n",
    "# predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "metrics_df = predictions[['productid', 'predictedyQuantity']].merge(actual, on=\"productid\")\n",
    "print(metrics_df.shape)\n",
    "metrics(metrics_df[\"yQuantity\"], metrics_df[\"predictedyQuantity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.sort_values(by=[\"yQuantity\"], ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA WomenKurtas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, actual = perform_pca_experiment(\"womenKurtas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "metrics_df = predictions[['productid', 'predictedyQuantity']].merge(actual, on=\"productid\")\n",
    "print(metrics_df.shape)\n",
    "metrics(metrics_df[\"yQuantity\"], metrics_df[\"predictedyQuantity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.sort_values(by=[\"yQuantity\"], ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N Months features MenShirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(of, experiment_function, **kwargs):\n",
    "    predictions, actual = experiment_function(of, **kwargs)\n",
    "    print(predictions.shape)\n",
    "    metrics_df = predictions[['productid', 'predictedyQuantity']].merge(actual, on=\"productid\")\n",
    "    print(metrics_df.shape)\n",
    "    metrics(metrics_df[\"yQuantity\"], metrics_df[\"predictedyQuantity\"])\n",
    "    print(metrics_df.sort_values(by=[\"yQuantity\"], ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_task(n, attributes):\n",
    "    run_experiment(\"menShirts\", perform_n_months_experiment, n=n, attributes=attributes)\n",
    "    run_experiment(\"womenKurtas\", perform_n_months_experiment, n=n, attributes=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_task(\n",
    "    n = 3,\n",
    "    attributes = [\"sales\", \"wishlist\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_task(\n",
    "    n = 4,\n",
    "    attributes = [\"sales\", \"wishlist\", \"availableQuantity\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
