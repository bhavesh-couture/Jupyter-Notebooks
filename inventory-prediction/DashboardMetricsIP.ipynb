{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure -f \n",
    "{\n",
    "    \"conf\":\n",
    "    {\n",
    "        \"spark.app.name\":\"Bhavesh_Relevancy_notebook\",\n",
    "        \"spark.yarn.queue\": \"default\",\n",
    "        \"spark.jars\": \"/apps/Jars/obelisk-retail-legos.jar,/apps/Jars/mysql-connector-java-5.1.40.jar\",\n",
    "        \"spark.driver.extraJavaOptions\": \"-Dscala.color\",\n",
    "        \"spark.driver.memory\": \"2g\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.instances\": \"4\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ai.couture.obelisk.commons.Constants._\n",
    "import ai.couture.obelisk.commons.Constants.STANDARD_COL_NAMES._\n",
    "import ai.couture.obelisk.commons.Constants._\n",
    "import ai.couture.obelisk.commons.io._\n",
    "import ai.couture.obelisk.commons.utils.DateTimeUtil._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.expressions._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.text.SimpleDateFormat\n",
    "import java.time.DayOfWeek.{MONDAY, SUNDAY}\n",
    "import java.time.format.DateTimeFormatter\n",
    "import java.time.format.DateTimeFormatter.ofPattern\n",
    "import java.time.temporal.TemporalAdjusters.previousOrSame\n",
    "import java.time.temporal.{ChronoUnit, WeekFields}\n",
    "import java.time.{LocalDate, LocalDateTime}\n",
    "import java.util.{Date, Locale, TimeZone}  \n",
    "def getFutureMonthDateFromHere(numMonths: Int, date: String, inputDateFormat: String,\n",
    "                                 outputDateFormat: String = \"yyyy-MM-dd\"): String = {\n",
    "    LocalDate.parse(date, ofPattern(inputDateFormat)).plusMonths(numMonths).format(ofPattern(outputDateFormat))\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "import java.time.format.DateTimeFormatter.ofPattern\n",
    "import java.time.temporal.{ChronoUnit}\n",
    "import java.time.{LocalDate}\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "  val getNumOfMonthsBetweenTwoDates = udf((startDate: String, endDate: String)=> {\n",
    "\n",
    "    val inputDateFormat: String = \"yyyy-MM-dd\"\n",
    "    val dateBefore: LocalDate = LocalDate.parse(startDate, ofPattern(inputDateFormat))\n",
    "\n",
    "    val dateAfter: LocalDate = LocalDate.parse(endDate, ofPattern(inputDateFormat))\n",
    "\n",
    "    ChronoUnit.MONTHS.between(dateBefore, dateAfter)\n",
    "\n",
    "  })\n",
    "\n",
    "  val getOldMonthDateFromHere = udf((numMonths: Int, date: String) => {\n",
    "      val inputDateFormat: String = \"yyyy-MM-dd\"\n",
    "    val outputDateFormat: String = \"yyyy-MM-dd\"\n",
    "\n",
    "    LocalDate.parse(date, ofPattern(inputDateFormat)).minusMonths(numMonths).format(ofPattern(outputDateFormat))\n",
    "  })\n",
    "\n",
    "\n",
    "    def getFutureMonthDateFromHere(numMonths: Int, date: String, inputDateFormat: String,\n",
    "                                 outputDateFormat: String = \"yyyy-MM-dd\"): String = {\n",
    "    LocalDate.parse(date, ofPattern(inputDateFormat)).plusMonths(numMonths).format(ofPattern(outputDateFormat))\n",
    "  }\n",
    "\n",
    "\n",
    "  def getFutureDateFromHere(numDays: Int, date: String, inputDateFormat: String,\n",
    "                            outputDateFormat: String = \"yyyy-MM-dd\"): String = {\n",
    "    LocalDate.parse(date, ofPattern(inputDateFormat)).plusDays(numDays).format(ofPattern(outputDateFormat))\n",
    "  }\n",
    "\n",
    "    def getOldDateFromHere(numDays: Int, date: String, inputDateFormat: String,\n",
    "                         outputDateFormat: String = \"yyyy-MM-dd\"): String = {\n",
    "    LocalDate.parse(date, ofPattern(inputDateFormat)).minusDays(numDays).format(ofPattern(outputDateFormat))\n",
    "  }\n",
    "\n",
    "  def getOldMonthDateFromHerenotUdf(numMonths: Int, date: String, inputDateFormat: String,\n",
    "                              outputDateFormat: String = \"yyyy-MM-dd\"): String = {\n",
    "    LocalDate.parse(date, ofPattern(inputDateFormat)).minusMonths(numMonths).format(ofPattern(outputDateFormat))\n",
    "  }\n",
    "\n",
    "var DATE=\"date\"\n",
    "var PREDICTED=\"predicted\"\n",
    "var ACTUAL=\"actual\"\n",
    "\n",
    "var rundate = \"2023-04-15\"\n",
    "var predictionend = getFutureMonthDateFromHere(1,rundate,\"yyyy-MM-dd\")\n",
    "var dateForWhichPredictionsMade = getFutureDateFromHere(1,rundate,\"yyyy-MM-dd\")\n",
    "var trainendDate =getOldDateFromHere(1,rundate,\"yyyy-MM-dd\")\n",
    "var trainStartDate = \"2022-01-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveNLoadDF(key: String)(df: DataFrame): DataFrame = {\n",
    "    var tempPath = \"/data/Archive/bhavesh/inventoryPrediction/temp/dashboard_metrics\"\n",
    "    DFToParquet.putDF(tempPath + \"/\" + key, df)\n",
    "    ParquetToDF.getDF(tempPath + \"/\" + key)\n",
    "  }\n",
    "\n",
    "def load(key: String): DataFrame = {\n",
    "    var tempPath = \"/data/Archive/bhavesh/inventoryPrediction/temp/dashboard_metrics\"\n",
    "    ParquetToDF.getDF(tempPath + \"/\" + key)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var productLevelDailyQuantity = ParquetToDF.getDF(\"/data/Archive/inventory/2023-04-15/queryProductMap_colorfamily_pricebucket_styletype_pattern_sleeve_brandname/productlevelquantity\")\n",
    "productLevelDailyQuantity.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var productLevelQuantity = (\n",
    "    productLevelDailyQuantity.filter(col(\"date\")>=trainStartDate && col(\"date\")<dateForWhichPredictionsMade).filter(!(col(\"date\")===rundate))\n",
    "    .withColumn(\"pastmonth\",getNumOfMonthsBetweenTwoDates(col(DATE),lit(trainendDate))+1)\n",
    "    .filter(col(\"pastmonth\") <= 15)\n",
    "    .groupBy(PRODUCTID)\n",
    "    .agg(sum(QUANTITY) as QUANTITY)\n",
    "    .transform(saveNLoadDF(\"productQuantityForPast15MonthsAggregated\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var ga = (\n",
    "    ParquetToDF.getDF(\"/data/ecomm/ajio/processed/ProcessedGAData\")\n",
    "    .select(PRODUCTID, \"PLPViewsPerDay\", DATE)\n",
    "    .filter(col(\"date\")>=trainStartDate && col(\"date\")<dateForWhichPredictionsMade).filter(!(col(\"date\")===rundate))\n",
    "    .withColumn(\"pastmonth\",getNumOfMonthsBetweenTwoDates(col(DATE),lit(trainendDate))+1)\n",
    "    .filter(col(\"pastmonth\") <= 15)\n",
    "    .groupBy(PRODUCTID)\n",
    "    .agg(sum(\"PLPViewsPerDay\") as \"impressions\")\n",
    "    .transform(saveNLoadDF(\"productImpressionsForPast15MonthsAggregated\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var productDetails = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/productDetails\")\n",
    "productDetails.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productDetails = productDetails.select(\"productid\").distinct().transform(saveNLoadDF(\"allProducts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var productMetrics = productDetails.join(productLevelQuantity, Seq(PRODUCTID), \"left\").join(ga, Seq(PRODUCTID), \"left\").na.fill(0).transform(saveNLoadDF(\"productLevelMetrics\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var productMetrics = load(\"productLevelMetrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var suffix = \"colorfamily_pricebucket_styletype_pattern_sleeve_brandname\"\n",
    "var queriesToProductMap = ParquetToDF.getDF(s\"/data/Archive/bhavesh/inventoryPrediction/queryToProductMap/date_when_prediction_is_made=$dateForWhichPredictionsMade/suffix=$suffix\").select(\"query\", \"productid\", \"similargrouplevel\", \"template\").na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var queryLevelMetrics = (\n",
    "    productMetrics.join(queriesToProductMap, Seq(PRODUCTID))\n",
    "    .groupBy(\"query\", \"similargrouplevel\", \"template\")\n",
    "    .agg(sum(QUANTITY).cast(DoubleType) as QUANTITY, sum(\"impressions\").cast(DoubleType) as \"impressions\")\n",
    "    .transform(saveNLoadDF(\"queryLevelMetrics\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryLevelMetrics.filter(col(\"query\") === \"4_full-length sleeve_black\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "778+480+465+531+804+718+654+477+1480+809+1065+1415+1258+1484+1223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryLevelMetrics.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var predictions = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/predictions\")\n",
    "predictions.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var impressions = (\n",
    "    predictions.select(\"query\", \"similargrouplevel\", \"predicted\", \"template\")\n",
    "    .join(queryLevelMetrics, Seq(\"query\", SIMILAR_GROUP_LEVEL, \"template\"), \"left\")\n",
    "    .withColumn(\"impressions\", when(col(\"impressions\") === 0 || col(\"quantity\") === 0, lit(null)).otherwise((col(\"predicted\") * col(\"impressions\"))/col(\"quantity\")))\n",
    "    .select(\"query\", \"similargrouplevel\", \"impressions\", \"template\")\n",
    ")\n",
    "\n",
    "DFToParquet.putDF(\"/data/Archive/bhavesh/inventoryPrediction/dashboardMetrics/impressions\", impressions)\n",
    "impressions = ParquetToDF.getDF(\"/data/Archive/bhavesh/inventoryPrediction/dashboardMetrics/impressions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impressions.filter(col(\"query\") === \"4_full-length sleeve_black\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var impressions = ParquetToDF.getDF(\"/data/Archive/bhavesh/inventoryPrediction/dashboardMetrics/impressions\")\n",
    "impressions.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var discountProductLevel = ParquetToDF.getDF(\"/data/Archive/inventory/2023-04-15/queryProductMap_colorfamily_pricebucket_styletype_pattern_sleeve_brandname/productDiscountDashboard\")\n",
    "discountProductLevel.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var discountQueryLevel = (\n",
    "    discountProductLevel.join(queriesToProductMap, Seq(PRODUCTID))\n",
    "    .groupBy(\"query\", \"similargrouplevel\", \"template\")\n",
    "    .agg(avg(\"WeightedAvgDiscount\").cast(DoubleType) as \"discount\")\n",
    "    .transform(saveNLoadDF(\"queryLevelDiscount\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discountQueryLevel.filter(col(\"query\") === \"4_full-length sleeve_black\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var discount = (\n",
    "    predictions.select(\"query\", \"similargrouplevel\", \"template\")\n",
    "    .join(discountQueryLevel, Seq(\"query\", SIMILAR_GROUP_LEVEL, \"template\"), \"left\")\n",
    "    .na.fill(0.0)\n",
    "    .select(\"query\", \"similargrouplevel\", \"discount\", \"template\")\n",
    ")\n",
    "\n",
    "DFToParquet.putDF(\"/data/Archive/bhavesh/inventoryPrediction/dashboardMetrics/discount\", discount)\n",
    "discount = ParquetToDF.getDF(\"/data/Archive/bhavesh/inventoryPrediction/dashboardMetrics/discount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impressions.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var dashboardMetrics = impressions.join(discount, Seq(\"query\", \"similargrouplevel\", \"template\"))\n",
    "println(dashboardMetrics.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFToParquet.putDF(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/dashboardMetrics\", dashboardMetrics)\n",
    "dashboardMetrics = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/dashboardMetrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.printSchema\n",
    "dashboardMetrics.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var predictionsWithDashboardMetrics = predictions.join(dashboardMetrics, Seq(\"query\", \"similargrouplevel\", \"template\"))\n",
    "predictionsWithDashboardMetrics.printSchema\n",
    "println(predictionsWithDashboardMetrics.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFToParquet.putDF(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/predictionsWithDashboardMetrics\", predictionsWithDashboardMetrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
