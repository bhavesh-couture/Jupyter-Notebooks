{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'Bhavesh_Demand_Forecast_Notebook', 'spark.yarn.queue': 'workflow', 'spark.jars': '/apps/Jars/obelisk-retail-legos-Bhavesh.jar,/apps/Jars/mysql-connector-java-5.1.40.jar', 'spark.driver.extraJavaOptions': '-Dscala.color', 'spark.driver.memory': '3g', 'spark.executor.memory': '3g', 'spark.executor.instances': '4'}, 'kind': 'spark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1415</td><td>application_1686980170466_0206</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://JMNGD1BAF370C10:8088/proxy/application_1686980170466_0206/\">Link</a></td><td><a target=\"_blank\" href=\"http://JMNGD1BAE210V09:8042/node/containerlogs/container_e114_1686980170466_0206_01_000001/couture\">Link</a></td><td></td></tr><tr><td>1416</td><td>application_1686980170466_0227</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://JMNGD1BAF370C10:8088/proxy/application_1686980170466_0227/\">Link</a></td><td><a target=\"_blank\" href=\"http://JMNGD1BAF070C08:8042/node/containerlogs/container_e114_1686980170466_0227_01_000001/couture\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f \n",
    "{\n",
    "    \"conf\":\n",
    "    {\n",
    "        \"spark.app.name\":\"Bhavesh_Demand_Forecast_Notebook\",\n",
    "        \"spark.yarn.queue\": \"workflow\",\n",
    "        \"spark.jars\": \"/apps/Jars/obelisk-retail-legos-Bhavesh.jar,/apps/Jars/mysql-connector-java-5.1.40.jar\",\n",
    "        \"spark.driver.extraJavaOptions\": \"-Dscala.color\",\n",
    "        \"spark.driver.memory\": \"3g\",\n",
    "        \"spark.executor.memory\": \"3g\",\n",
    "        \"spark.executor.instances\": \"4\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1417</td><td>application_1686980170466_0228</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://JMNGD1BAF370C10:8088/proxy/application_1686980170466_0228/\">Link</a></td><td><a target=\"_blank\" href=\"http://JMNGD1BAF070C08:8042/node/containerlogs/container_e114_1686980170466_0228_01_000001/couture\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import ai.couture.obelisk.commons.Constants._\n",
      "import ai.couture.obelisk.commons.Constants.STANDARD_COL_NAMES._\n",
      "import ai.couture.obelisk.commons.Constants._\n",
      "import ai.couture.obelisk.commons.io._\n",
      "import ai.couture.obelisk.commons.utils.DateTimeUtil._\n",
      "import ai.couture.obelisk.commons.utils.DataFrameUtil.minMaxScaler\n",
      "import org.apache.spark.sql._\n",
      "import org.apache.spark.sql.expressions._\n",
      "import org.apache.spark.sql.functions._\n",
      "import org.apache.spark.sql.types._\n",
      "import spark.implicits._\n"
     ]
    }
   ],
   "source": [
    "import ai.couture.obelisk.commons.Constants._\n",
    "import ai.couture.obelisk.commons.Constants.STANDARD_COL_NAMES._\n",
    "import ai.couture.obelisk.commons.Constants._\n",
    "import ai.couture.obelisk.commons.io._\n",
    "import ai.couture.obelisk.commons.utils.DateTimeUtil._\n",
    "import ai.couture.obelisk.commons.utils.DataFrameUtil.minMaxScaler\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.expressions._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mbaseDir\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = /data/Archive/bhavesh/InventoryPrediction\n",
      "\u001b[1m\u001b[34mrunDate\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2023-04-30\n",
      "\u001b[1m\u001b[34mrunDir\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = /data/Archive/bhavesh/InventoryPrediction/2023-04-30\n",
      "\u001b[1m\u001b[34mdataStartDate\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2022-02-01\n",
      "\u001b[1m\u001b[34mpredictionStart\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2023-05-01\n",
      "\u001b[1m\u001b[34mpredictionEnd\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2023-05-31\n",
      "\u001b[1m\u001b[34mtrainStart\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2022-04-01\n",
      "\u001b[1m\u001b[34mtrainEnd\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2023-04-29\n",
      "\u001b[1m\u001b[34mtrainXStart\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2022-04-01\n",
      "\u001b[1m\u001b[34mtrainXEnd\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2023-03-30\n",
      "\u001b[1m\u001b[34mtrainYStart\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2023-04-01\n",
      "\u001b[1m\u001b[34mtrainYEnd\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2023-04-30\n",
      "\u001b[1m\u001b[34mtestXStart\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2022-05-01\n",
      "\u001b[1m\u001b[34mtestXEnd\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2023-04-29\n",
      "\u001b[1m\u001b[34mtestYStart\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2023-05-01\n",
      "\u001b[1m\u001b[34mtestYEnd\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2023-05-31\n",
      "\u001b[1m\u001b[34msuffix\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = colorfamily_pricebucket_styletype_pattern_sleeve_brandname\n",
      "\u001b[1m\u001b[34mPREDICTED\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = predicted\n",
      "\u001b[1m\u001b[34mACTUAL\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = actual\n",
      "\u001b[1m\u001b[34mgetOldDateFromHereUDF\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.expressions.UserDefinedFunction\u001b[0m = UserDefinedFunction(<function4>,StringType,Some(List(IntegerType, StringType, StringType, StringType)))\n",
      "\u001b[1m\u001b[34mgetMonths\u001b[0m: \u001b[1m\u001b[32m(dateFormat: String)(df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "var baseDir = \"/data/Archive/bhavesh/InventoryPrediction\"\n",
    "var runDate = \"2023-04-30\"\n",
    "var runDir = s\"$baseDir/$runDate\"\n",
    "\n",
    "// 15 months of train data for arima\n",
    "var dataStartDate = \"2022-02-01\"\n",
    "var predictionStart = \"2023-05-01\"\n",
    "var predictionEnd = \"2023-05-31\"\n",
    "\n",
    "var trainStart = \"2022-04-01\"\n",
    "var trainEnd = \"2023-04-29\"\n",
    "\n",
    "var trainXStart = \"2022-04-01\"\n",
    "var trainXEnd = \"2023-03-30\"\n",
    "var trainYStart = \"2023-04-01\"\n",
    "var trainYEnd = \"2023-04-29\"\n",
    "\n",
    "var testXStart = \"2022-05-01\"\n",
    "var testXEnd = \"2023-04-29\"\n",
    "var testYStart = \"2023-05-01\"\n",
    "var testYEnd = \"2023-05-31\"\n",
    "\n",
    "var suffix = \"colorfamily_pricebucket_styletype_pattern_sleeve_brandname\"\n",
    "\n",
    "val PREDICTED=\"predicted\"\n",
    "val ACTUAL=\"actual\"\n",
    "\n",
    "val getOldDateFromHereUDF = udf((numDays: Int, date: String, inputDateFormat: String, outputDateFormat: String) => {\n",
    "    getOldDateFromHere(numDays, date, inputDateFormat, outputDateFormat)\n",
    "})\n",
    "\n",
    "def getMonths(dateFormat: String)(df: DataFrame): DataFrame = {\n",
    "    df.withColumn(\"dateFormatted\", getOldDateFromHereUDF(lit(0), col(DATE), lit(dateFormat), lit(\"yyyy-MM-dd\")))\n",
    "    .withColumn(\"year\", split(col(\"dateFormatted\"), \"-\")(0))\n",
    "    .withColumn(\"month\", split(col(\"dateFormatted\"), \"-\")(1))\n",
    "    .withColumn(\"monthsInHis\", dense_rank().over(Window.orderBy(desc(\"year\"), desc(\"month\"))) - lit(1))\n",
    "    .drop(\"dateFormatted\", \"year\", \"month\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Attributes && QueryProductMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var productAttrs = ParquetToDF.getDF(\"/data/Archive/inventory/2023-04-30/queryProductMap_colorfamily_pricebucket_styletype_pattern_sleeve_brandname/processedProductAttr\")\n",
    "productAttrs.printSchema\n",
    "\n",
    "DFToParquet.putDF(s\"$runDir/ProductAttributes\", productAttrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var queryToProductMap = ParquetToDF.getDF(s\"/data/ecomm/ajio/processed/inventory/2023-04-30/queryProductMap_$suffix\")\n",
    "queryToProductMap.printSchema\n",
    "\n",
    "DFToParquet.putDF(s\"$runDir/QueryProductMapping/suffix=$suffix\", queryToProductMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Level Daily/Monthly Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mproductAttrs\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m = [productid: string]\n",
      "\u001b[1m\u001b[34minteractionsDB\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [productid: string, date: date ... 1 more field]\n",
      "\u001b[1m\u001b[34mproductDailyQuantity\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [productid: string, date: date ... 1 more field]\n"
     ]
    }
   ],
   "source": [
    "var productAttrs = ParquetToDF.getDF(s\"$runDir/ProductAttributes\").select(PRODUCTID).distinct()\n",
    "\n",
    "var interactionsDB = (\n",
    "    ParquetToDF.getDF(\"/data/ecomm/ajio/processed/interactionsDB\")\n",
    "    .filter(col(\"event\") === \"Checkout\" && col(\"purchase\") === \"New\" \n",
    "            && col(\"productid\").isNotNull && col(\"booked_rev\") > 0 \n",
    "            && col(\"userid\").isNotNull && col(\"quantity\") > 0 \n",
    "            && col(\"date\")<=predictionEnd && col(\"date\")>=dataStartDate\n",
    "            && col(\"date\") =!= runDate\n",
    "           )\n",
    "    .groupBy(\"productid\", \"date\")\n",
    "    .agg(sum(\"quantity\").cast(DoubleType).as(\"quantity\"))\n",
    ")\n",
    "\n",
    "DFToParquet.putDF(s\"$runDir/DailyQuantity/product\", interactionsDB.join(productAttrs, Seq(PRODUCTID)))\n",
    "\n",
    "var productDailyQuantity = ParquetToDF.getDF(s\"$runDir/DailyQuantity/product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mmonthMap\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [monthsInHis: int, tempDateForTimeSeries: date]\n",
      "\u001b[1m\u001b[34mproductMonthlyQuantity\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [monthsInHis: int, productid: string ... 2 more fields]\n"
     ]
    }
   ],
   "source": [
    "var monthMap = ParquetToDF.getDF(\"/data/Archive/bhavesh/InventoryPrediction/2023-04-30/MonthsInHistoryMap\").select(col(\"monthsInHis\"), col(\"monthStartDate\").as(\"tempDateForTimeSeries\"))\n",
    "\n",
    "var productMonthlyQuantity = (\n",
    "    ParquetToDF.getDF(s\"$runDir/DailyQuantity/product\").transform(getMonths(\"yyyy-MM-dd\")).filter(col(\"monthsInHis\") <= 15)\n",
    "    .groupBy(PRODUCTID, \"monthsInHis\")\n",
    "    .agg(sum(\"quantity\") as \"quantity\")\n",
    "    .join(monthMap, Seq(\"monthsInHis\"))\n",
    ")\n",
    "\n",
    "DFToParquet.putDF(s\"$runDir/MonthlyQuantity/product\", productMonthlyQuantity.repartition(210))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mqueryProductMap\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [query: string, productid: string ... 2 more fields]\n",
      "\u001b[1m\u001b[34mqueryDailyQuantity\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [similargrouplevel: int, query: string ... 3 more fields]\n"
     ]
    }
   ],
   "source": [
    "var queryProductMap = ParquetToDF.getDF(s\"$runDir/QueryProductMapping/suffix=$suffix\").na.drop()\n",
    "\n",
    "var queryDailyQuantity = (\n",
    "    ParquetToDF.getDF(s\"$runDir/DailyQuantity/product\")\n",
    "    .join(queryProductMap, Seq(PRODUCTID))\n",
    "    .groupBy(\"similargrouplevel\", \"query\", \"template\", \"date\")\n",
    "    .agg(sum(\"quantity\") as \"quantity\")\n",
    ")\n",
    "DFToParquet.putDF(s\"$runDir/DailyQuantity/query\", queryDailyQuantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e148fc85a448e48d6a803cfcc66a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var monthMap = ParquetToDF.getDF(\"/data/Archive/bhavesh/InventoryPrediction/2023-04-30/MonthsInHistoryMap\").select(col(\"monthsInHis\"), col(\"monthStartDate\").as(\"tempDateForTimeSeries\"))\n",
    "\n",
    "var queryMonthlyQuantity = (\n",
    "    ParquetToDF.getDF(s\"$runDir/DailyQuantity/query\").transform(getMonths(\"yyyy-MM-dd\")).filter(col(\"monthsInHis\") <= 15)\n",
    "    .groupBy(\"similargrouplevel\", \"query\", \"template\", \"monthsInHis\")\n",
    "    .agg(sum(\"quantity\") as \"quantity\")\n",
    "    .join(monthMap, Seq(\"monthsInHis\"))\n",
    ")\n",
    "DFToParquet.putDF(s\"$runDir/MonthlyQuantity/query\", queryMonthlyQuantity.repartition(210))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction space Products/queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var productMonthlyQuantity = ParquetToDF.getDF(s\"$runDir/MonthlyQuantity/product\")\n",
    "\n",
    "var productsToPredict = productMonthlyQuantity.filter(col(\"monthsInHis\") >= 1 && col(\"monthsInHis\") <= 12).select(PRODUCTID).distinct()\n",
    "DFToParquet.putDF(s\"$runDir/PredictionSpace/products\", productsToPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mqueryProductMap\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m = [query: string, productid: string ... 2 more fields]\n",
      "\u001b[1m\u001b[34mqueriesToPredict\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m = [similargrouplevel: int, query: string ... 1 more field]\n"
     ]
    }
   ],
   "source": [
    "var queryProductMap = ParquetToDF.getDF(s\"$runDir/QueryProductMapping/suffix=$suffix\").na.drop().filter(col(\"query\") =!= \"\")\n",
    "\n",
    "var queriesToPredict = (\n",
    "    ParquetToDF.getDF(s\"$runDir/PredictionSpace/products\")\n",
    "    .join(queryProductMap, Seq(PRODUCTID))\n",
    "    .select(\"similargrouplevel\", \"query\", \"template\")\n",
    "    .distinct()\n",
    ")\n",
    "DFToParquet.putDF(s\"$runDir/PredictionSpace/queries\", queriesToPredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard deviation for products/queries based on 12 months data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var productMonthlyQuantity = ParquetToDF.getDF(s\"$runDir/MonthlyQuantity/product\")\n",
    "\n",
    "var productSigma = (\n",
    "    productMonthlyQuantity.filter(col(\"monthsInHis\") >= 1 && col(\"monthsInHis\") <=12)\n",
    "    .drop(\"tempDateForTimeSeries\")\n",
    "    .groupBy(PRODUCTID).agg(stddev(\"quantity\").as(\"stddev\"),avg(\"quantity\").as(\"avg\")).na.fill(0.0, Seq(\"stddev\"))\n",
    ")\n",
    "\n",
    "DFToParquet.putDF(s\"$runDir/Statistics12Months/product\", productSigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var queryMonthlyQuantity = ParquetToDF.getDF(s\"$runDir/MonthlyQuantity/query\")\n",
    "\n",
    "var querySigma = (\n",
    "    queryMonthlyQuantity.filter(col(\"monthsInHis\") >= 1 && col(\"monthsInHis\") <=12)\n",
    "    .drop(\"tempDateForTimeSeries\")\n",
    "    .groupBy(\"similargrouplevel\", \"query\", \"template\").agg(stddev(\"quantity\").as(\"stddev\"),avg(\"quantity\").as(\"avg\")).na.fill(0.0, Seq(\"stddev\"))\n",
    ")\n",
    "\n",
    "DFToParquet.putDF(s\"$runDir/Statistics12Months/query\", querySigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var actualProduct = (\n",
    "    ParquetToDF.getDF(s\"$runDir/MonthlyQuantity/product\")\n",
    "    .filter(col(\"monthsInHis\") === 0)\n",
    "    .select(col(PRODUCTID), col(\"quantity\").alias(\"sales\"))\n",
    ")\n",
    "\n",
    "DFToParquet.putDF(s\"$runDir/Actual/sales/product\", actualProduct)\n",
    "\n",
    "var queryProductMap = ParquetToDF.getDF(s\"$runDir/QueryProductMapping/suffix=$suffix\").na.drop()\n",
    "var actualQuery = (\n",
    "    ParquetToDF.getDF(s\"$runDir/Actual/sales/product\")\n",
    "    .join(queryProductMap, Seq(PRODUCTID))\n",
    "    .groupBy(\"similargrouplevel\", \"query\", \"template\")\n",
    "    .agg(sum(\"sales\") as \"sales\")\n",
    ")\n",
    "\n",
    "DFToParquet.putDF(s\"$runDir/Actual/sales/query\", actualQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mactualQuery\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [similargrouplevel: int, query: string ... 2 more fields]\n",
      "root\n",
      " |-- similargrouplevel: integer (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- template: string (nullable = true)\n",
      " |-- sales: double (nullable = true)\n",
      "\n",
      "\u001b[1m\u001b[34mqueriesToPredict\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [similargrouplevel: int, query: string ... 1 more field]\n",
      "root\n",
      " |-- similargrouplevel: integer (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- template: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var actualQuery = ParquetToDF.getDF(s\"$runDir/Actual/sales/query\")\n",
    "actualQuery.printSchema\n",
    "\n",
    "var queriesToPredict = ParquetToDF.getDF(s\"$runDir/PredictionSpace/queries\")\n",
    "queriesToPredict.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mtarget\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [productid: string, yQuantity: double]\n",
      "root\n",
      " |-- productid: string (nullable = true)\n",
      " |-- yQuantity: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var target = ParquetToDF.getDF(s\"$runDir/MonthlyQuantity/product\").filter(col(\"monthsInHis\") === 1).select(col(\"productid\"), col(\"quantity\").alias(\"yQuantity\"))\n",
    "target.printSchema\n",
    "\n",
    "DFToParquet.putDF(s\"$runDir/dataset/train/target\", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [productid: string, yQuantity: bigint ... 6 more fields]\n",
      "root\n",
      " |-- productid: string (nullable = true)\n",
      " |-- yQuantity: long (nullable = true)\n",
      " |-- similargrouplevel: string (nullable = true)\n",
      " |-- colorfamily: string (nullable = true)\n",
      " |-- brandname: string (nullable = true)\n",
      " |-- sleeve: string (nullable = true)\n",
      " |-- pattern: string (nullable = true)\n",
      " |-- styletype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var df = ParquetToDF.getDF(\"/data/Archive/bhavesh/inventoryPrediction-deprecated/embeddings/data\")\n",
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mtarget\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [productid: string, yQuantity: double]\n",
      "root\n",
      " |-- productid: string (nullable = true)\n",
      " |-- yQuantity: double (nullable = true)\n",
      "\n",
      "\u001b[1m\u001b[34mproductAttrs\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [productid: string, similargrouplevel: string ... 5 more fields]\n",
      "root\n",
      " |-- productid: string (nullable = true)\n",
      " |-- similargrouplevel: string (nullable = true)\n",
      " |-- colorfamily: string (nullable = true)\n",
      " |-- brandname: string (nullable = true)\n",
      " |-- sleeve: string (nullable = true)\n",
      " |-- pattern: string (nullable = true)\n",
      " |-- styletype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var target = ParquetToDF.getDF(s\"$runDir/dataset/train/target\")\n",
    "target.printSchema\n",
    "\n",
    "var productAttrs = ParquetToDF.getDF(s\"$runDir/ProductAttributes\").select(PRODUCTID, \"similargrouplevel\", \"colorfamily\", \"brandname\", \"sleeve\", \"pattern\", \"styletype\")\n",
    "productAttrs.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34membeddingsData\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [productid: string, similargrouplevel: string ... 6 more fields]\n",
      "root\n",
      " |-- productid: string (nullable = true)\n",
      " |-- similargrouplevel: string (nullable = true)\n",
      " |-- colorfamily: string (nullable = true)\n",
      " |-- brandname: string (nullable = true)\n",
      " |-- sleeve: string (nullable = true)\n",
      " |-- pattern: string (nullable = true)\n",
      " |-- styletype: string (nullable = true)\n",
      " |-- yQuantity: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var embeddingsData = productAttrs.join(target, Seq(PRODUCTID))\n",
    "embeddingsData.printSchema\n",
    "\n",
    "DFToParquet.putDF(s\"$runDir/Embeddings/data\", embeddingsData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mdatasetDir\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = /data/Archive/bhavesh/InventoryPrediction/2023-04-30/dataset\n",
      "\u001b[1m\u001b[34mproductAttrs\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m = [productid: string, similargrouplevel: string]\n",
      "\u001b[1m\u001b[34msaveNLoadDF\u001b[0m: \u001b[1m\u001b[32m(path: String)(df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\u001b[0m\n",
      "\u001b[1m\u001b[34mgetMonthlyMeanStd\u001b[0m: \u001b[1m\u001b[32m(monthsLimit: Int, colsForStatistics: Array[String], calculateStd: Boolean)(df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "var datasetDir = s\"$runDir/dataset\"\n",
    "var productAttrs = (\n",
    "    ParquetToDF.getDF(s\"$runDir/ProductAttributes\").select(col(PRODUCTID), col(SIMILAR_GROUP_LEVEL))\n",
    "    .dropDuplicates(PRODUCTID)\n",
    "    .filter(col(SIMILAR_GROUP_LEVEL).isin(\"830216013\", \"830303011\"))\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "def saveNLoadDF(path: String)(df: DataFrame): DataFrame = {\n",
    "    DFToParquet.putDF(path, df)\n",
    "    ParquetToDF.getDF(path)\n",
    "}\n",
    "\n",
    "def getMonthlyMeanStd(monthsLimit: Int, colsForStatistics: Array[String], calculateStd: Boolean)(df: DataFrame): DataFrame = {\n",
    "    var intermediateDF = df\n",
    "    val monthsArray = (0 until monthsLimit).toArray\n",
    "    val colsToUseForCalculations = colsForStatistics.map(column => (column, monthsArray.map(month => s\"${month}_${column}\"))).toMap\n",
    "    colsToUseForCalculations.foreach(\n",
    "        columnInfo => {\n",
    "            val attr = columnInfo._1\n",
    "            val colsToUse = columnInfo._2\n",
    "            val meanExpr = colsToUse.map(col).reduce((col1, col2) => col1 + col2)\n",
    "            intermediateDF = intermediateDF.withColumn(s\"${attr}_avg_${monthsLimit}_months\", meanExpr/lit(colsToUse.length).cast(DoubleType))\n",
    "            \n",
    "            if(calculateStd){\n",
    "                print(attr)\n",
    "                val stdExpr = colsToUse.map(column => pow(col(column) - col(s\"${attr}_avg_${monthsLimit}_months\"), lit(2)))\n",
    "                .reduce((col1, col2) => col1 + col2)\n",
    "                intermediateDF = intermediateDF.withColumn(s\"${attr}_std_${monthsLimit}_months\",\n",
    "                                                           sqrt(stdExpr/lit(colsToUse.length - 1)))\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    intermediateDF\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mgenerateSalesXData\u001b[0m: \u001b[1m\u001b[32m(of: String, startDate: String, endDate: String, productAttrs: org.apache.spark.sql.DataFrame, baseDir: String)Unit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def generateSalesXData(of: String, startDate: String, endDate: String, productAttrs: DataFrame, baseDir: String): Unit = {\n",
    "\n",
    "    val features = Array(\"sales\")\n",
    "    val tempDir = \"/data/Archive/bhavesh/InventoryPrediction/temp/generateSalesXData\"\n",
    "    \n",
    "    var interactions = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/interactionsDB\")\n",
    "    .filter(col(\"event\") === \"Checkout\" && col(\"purchase\") === \"New\" \n",
    "            && col(\"productid\").isNotNull && col(\"booked_rev\") > 0 \n",
    "            && col(\"userid\").isNotNull && col(\"quantity\") > 0\n",
    "            && col(DATE).between(startDate, endDate)\n",
    "           )\n",
    "    .groupBy(PRODUCTID, DATE)\n",
    "    .agg(sum(QUANTITY) as \"sales\")\n",
    "    .join(productAttrs, Seq(PRODUCTID))\n",
    "    .transform(saveNLoadDF(s\"$tempDir/interactions_1\"))\n",
    "    .transform(getMonths(\"yyyy-MM-dd\"))\n",
    "    .filter(col(\"monthsInHis\") < 12)\n",
    "    .groupBy(PRODUCTID)\n",
    "    .pivot(\"monthsInHis\")\n",
    "    .agg(sum(\"sales\").cast(DoubleType) as \"sales\", first(\"sales\") as \"temp\")\n",
    "    \n",
    "    val colsToDrop = interactions.columns.filter(_.endsWith(\"temp\"))\n",
    "    interactions = interactions.drop(colsToDrop: _*).na.fill(0)\n",
    "    .transform(saveNLoadDF(s\"$tempDir/interactions_2\"))\n",
    "    .transform(getMonthlyMeanStd(3, Array(\"sales\"), false))\n",
    "    .transform(getMonthlyMeanStd(6, Array(\"sales\"), false))\n",
    "    .transform(getMonthlyMeanStd(12, Array(\"sales\"), true))\n",
    "    \n",
    "    DFToParquet.putDF(s\"$baseDir/$of/sales\", interactions)\n",
    "    HdfsUtils.delete(tempDir)\n",
    "}\n",
    "\n",
    "generateSalesXData(\"train\", trainXStart, trainXEnd, productAttrs, datasetDir)\n",
    "generateSalesXData(\"test\", testXStart, testXEnd, productAttrs, datasetDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mgenerateGAXData\u001b[0m: \u001b[1m\u001b[32m(of: String, startDate: String, endDate: String, productAttrs: org.apache.spark.sql.DataFrame, baseDir: String)Unit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def generateGAXData(of: String, startDate: String, endDate: String, productAttrs: DataFrame, baseDir: String): Unit = {\n",
    "\n",
    "    val features = Array(\"PLPViewsPerDay\", \"PLPClicksPerDay\", \"PDPCountPerDay\", \"TotalAddToCartPerDay\")\n",
    "    val aggExprs = features.map(feature => sum(feature).cast(DoubleType).alias(feature))\n",
    "    val tempDir = \"/data/Archive/bhavesh/InventoryPrediction/temp/generateGAXData\"\n",
    "    \n",
    "    val ga = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/ProcessedGAData\")\n",
    "    .filter(col(DATE).between(startDate, endDate))\n",
    "    .groupBy(PRODUCTID, DATE)\n",
    "    .agg(aggExprs.head, aggExprs.tail: _*)\n",
    "    .join(productAttrs, Seq(PRODUCTID))\n",
    "    .transform(saveNLoadDF(s\"$tempDir/ga_1\"))\n",
    "    .transform(getMonths(\"yyyy-MM-dd\"))\n",
    "    .filter(col(\"monthsInHis\") < 12)\n",
    "    .groupBy(PRODUCTID)\n",
    "    .pivot(\"monthsInHis\")\n",
    "    .agg(aggExprs.head, aggExprs.tail: _*)\n",
    "    .na.fill(0)\n",
    "    .transform(saveNLoadDF(s\"$tempDir/ga_2\"))\n",
    "    .transform(getMonthlyMeanStd(3, features, false))\n",
    "    .transform(getMonthlyMeanStd(6, features, false))\n",
    "    .transform(getMonthlyMeanStd(12, features, true))\n",
    "    \n",
    "    DFToParquet.putDF(s\"$baseDir/$of/ga\", ga)\n",
    "    HdfsUtils.delete(tempDir)\n",
    "}\n",
    "\n",
    "generateGAXData(\"train\", trainXStart, trainXEnd, productAttrs, datasetDir)\n",
    "generateGAXData(\"test\", testXStart, testXEnd, productAttrs, datasetDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mgenerateWishlistData\u001b[0m: \u001b[1m\u001b[32m(of: String, startDate: String, endDate: String, productAttrs: org.apache.spark.sql.DataFrame, baseDir: String)Unit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def generateWishlistData(of: String, startDate: String, endDate: String, productAttrs: DataFrame, baseDir: String): Unit = {\n",
    "    val features = Array(\"wishlist\")\n",
    "    val tempDir = \"/data/Archive/bhavesh/InventoryPrediction/temp/generateWishlistData\"\n",
    "    \n",
    "    var wishlist = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/processedWishlist\")\n",
    "    .filter(col(DATE).between(startDate, endDate))\n",
    "    .groupBy(PRODUCTID, DATE)\n",
    "    .agg(countDistinct(\"wishlistid\").cast(DoubleType) as \"wishlist\")\n",
    "    .join(productAttrs, Seq(PRODUCTID))\n",
    "    .transform(saveNLoadDF(s\"$tempDir/wishlist_1\"))\n",
    "    .transform(getMonths(\"yyyy-MM-dd\"))\n",
    "    .filter(col(\"monthsInHis\") < 12)\n",
    "    .groupBy(PRODUCTID)\n",
    "    .pivot(\"monthsInHis\")\n",
    "    .agg(sum(\"wishlist\") as \"wishlist\", first(\"wishlist\") as \"temp\")\n",
    "    \n",
    "    val colsToDrop = wishlist.columns.filter(_.endsWith(\"temp\"))\n",
    "    wishlist = wishlist.drop(colsToDrop: _*).na.fill(0)\n",
    "    .transform(saveNLoadDF(s\"$tempDir/wishlist_2\"))\n",
    "    .transform(getMonthlyMeanStd(3, features, false))\n",
    "    .transform(getMonthlyMeanStd(6, features, false))\n",
    "    // .transform(getMonthlyMeanStd(12, features, true))\n",
    "    \n",
    "    DFToParquet.putDF(s\"$baseDir/$of/wishlist\", wishlist)\n",
    "    HdfsUtils.delete(tempDir)\n",
    "}\n",
    "generateWishlistData(\"train\", trainXStart, trainXEnd, productAttrs, datasetDir)\n",
    "generateWishlistData(\"test\", testXStart, testXEnd, productAttrs, datasetDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mgenerateReturnsData\u001b[0m: \u001b[1m\u001b[32m(of: String, startDate: String, endDate: String, productAttrs: org.apache.spark.sql.DataFrame, baseDir: String)Unit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def generateReturnsData(of: String, startDate: String, endDate: String, productAttrs: DataFrame, baseDir: String): Unit = {\n",
    "    val features = Array(\"returns\")\n",
    "    val tempDir = \"/data/Archive/bhavesh/InventoryPrediction/temp/generateReturns\"\n",
    "    \n",
    "    var returns = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/interactionsDB\")\n",
    "    .filter(col(\"event\") === \"Return\" && col(QUANTITY) >= 0 &&\n",
    "        col(USERID).isNotNull && col(PRODUCTID).isNotNull)\n",
    "    .filter(col(DATE).between(startDate, endDate))\n",
    "    .groupBy(PRODUCTID, DATE)\n",
    "    .agg(sum(QUANTITY).cast(DoubleType) as \"returns\")\n",
    "    .join(productAttrs, Seq(PRODUCTID))\n",
    "    .transform(saveNLoadDF(s\"$tempDir/returns_1\"))\n",
    "    .transform(getMonths(\"yyyy-MM-dd\"))\n",
    "    .filter(col(\"monthsInHis\") < 12)\n",
    "    .groupBy(PRODUCTID)\n",
    "    .pivot(\"monthsInHis\")\n",
    "    .agg(sum(\"returns\") as \"returns\", first(\"returns\") as \"temp\")\n",
    "    \n",
    "    val colsToDrop = returns.columns.filter(_.endsWith(\"temp\"))\n",
    "    returns = returns.drop(colsToDrop: _*).na.fill(0)\n",
    "    .transform(saveNLoadDF(s\"$tempDir/returns_2\"))\n",
    "    .transform(getMonthlyMeanStd(3, features, false))\n",
    "    .transform(getMonthlyMeanStd(6, features, false))\n",
    "    .transform(getMonthlyMeanStd(12, features, true))\n",
    "    \n",
    "    DFToParquet.putDF(s\"$baseDir/$of/returns\", returns)\n",
    "    HdfsUtils.delete(tempDir)\n",
    "}\n",
    "generateReturnsData(\"train\", trainXStart, trainXEnd, productAttrs, datasetDir)\n",
    "generateReturnsData(\"test\", testXStart, testXEnd, productAttrs, datasetDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mgenerateUsersData\u001b[0m: \u001b[1m\u001b[32m(of: String, startDate: String, endDate: String, productAttrs: org.apache.spark.sql.DataFrame, baseDir: String)Unit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def generateUsersData(of: String, startDate: String, endDate: String, productAttrs: DataFrame, baseDir: String): Unit = {\n",
    "    val features = Array(\"users\")\n",
    "    val tempDir = \"/data/Archive/bhavesh/InventoryPrediction/temp/generateUsersData\"\n",
    "    \n",
    "    var interactions = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/interactionsDB\")\n",
    "    .filter(col(\"event\") === \"Checkout\" && col(\"purchase\") === \"New\" \n",
    "            && col(\"productid\").isNotNull && col(\"booked_rev\") > 0 \n",
    "            && col(\"userid\").isNotNull && col(\"quantity\") > 0\n",
    "            && col(DATE).between(startDate, endDate)\n",
    "           )\n",
    "    .join(productAttrs, Seq(PRODUCTID))\n",
    "    .transform(saveNLoadDF(s\"$tempDir/interactions_1\"))\n",
    "    .transform(getMonths(\"yyyy-MM-dd\"))\n",
    "    .filter(col(\"monthsInHis\") < 12)\n",
    "    .groupBy(PRODUCTID)\n",
    "    .pivot(\"monthsInHis\")\n",
    "    .agg(countDistinct(USERID).cast(DoubleType) as \"users\", first(USERID) as \"temp\")\n",
    "    \n",
    "    val colsToDrop = interactions.columns.filter(_.endsWith(\"temp\"))\n",
    "    interactions = interactions.drop(colsToDrop: _*).na.fill(0)\n",
    "    .transform(saveNLoadDF(s\"$tempDir/interactions_2\"))\n",
    "    .transform(getMonthlyMeanStd(3, features, false))\n",
    "    .transform(getMonthlyMeanStd(6, features, false))\n",
    "    .transform(getMonthlyMeanStd(12, features, true))\n",
    "    \n",
    "    DFToParquet.putDF(s\"$baseDir/$of/users\", interactions)\n",
    "    HdfsUtils.delete(tempDir)\n",
    "}\n",
    "generateUsersData(\"train\", trainXStart, trainXEnd, productAttrs, datasetDir)\n",
    "generateUsersData(\"test\", testXStart, testXEnd, productAttrs, datasetDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mgenerateAvailabilityQuantityData\u001b[0m: \u001b[1m\u001b[32m(of: String, startDate: String, endDate: String, productAttrs: org.apache.spark.sql.DataFrame, baseDir: String)Unit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def generateAvailabilityQuantityData(of: String, startDate: String, endDate: String, productAttrs: DataFrame, baseDir: String): Unit = {\n",
    "    val features = Array(\"totalAvailableQuantity\", \"maxAvailableQuantity\")\n",
    "    val tempDir = \"/data/Archive/bhavesh/InventoryPrediction/temp/generateAvailabilityQuantityData\"\n",
    "    \n",
    "    var inventory = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/LiveProductsInventoryHistoryLegos\")\n",
    "    .withColumnRenamed(ITEM_ID, PRODUCTID)\n",
    "    .filter(col(DATE).between(startDate, endDate))\n",
    "    .groupBy(PRODUCTID, DATE)\n",
    "    .agg(sum(\"availablequantity\").as(\"availableQuantity\"))\n",
    "    .join(productAttrs, Seq(PRODUCTID))\n",
    "    .transform(saveNLoadDF(s\"$tempDir/inventory_1\"))\n",
    "    .transform(getMonths(\"yyyy-MM-dd\"))\n",
    "    .filter(col(\"monthsInHis\") < 12)\n",
    "    .groupBy(PRODUCTID)\n",
    "    .pivot(\"monthsInHis\")\n",
    "    .agg(sum(\"availableQuantity\").cast(DoubleType) as \"totalAvailableQuantity\", max(\"availableQuantity\") as \"maxAvailableQuantity\")\n",
    "    \n",
    "    inventory = inventory.na.fill(0)\n",
    "    .transform(saveNLoadDF(s\"$tempDir/inventory_2\"))\n",
    "    .transform(getMonthlyMeanStd(3, features, false))\n",
    "    .transform(getMonthlyMeanStd(6, features, false))\n",
    "    .transform(getMonthlyMeanStd(12, features, true))\n",
    "    \n",
    "    DFToParquet.putDF(s\"$baseDir/$of/availableQuantity\", inventory)\n",
    "    HdfsUtils.delete(tempDir)\n",
    "}\n",
    "generateAvailabilityQuantityData(\"train\", trainXStart, trainXEnd, productAttrs, datasetDir)\n",
    "generateAvailabilityQuantityData(\"test\", testXStart, testXEnd, productAttrs, datasetDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mCreateDataset\u001b[0m: \u001b[1m\u001b[32m(of: String, xPath: String, yPath: String, basePath: String)Unit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def CreateDataset(of: String, xPath: String, yPath: String, basePath: String): Unit = {\n",
    "    val tempDir = \"/data/Archive/bhavesh/InventoryPrediction/temp/createDataset\"\n",
    "    var xData = ParquetToDF.getDF(s\"$xPath/$of/sales\").drop(SIMILAR_GROUP_LEVEL)\n",
    "    .join(ParquetToDF.getDF(s\"$xPath/$of/ga\").drop(SIMILAR_GROUP_LEVEL), Seq(PRODUCTID), \"outer\")\n",
    "    .transform(saveNLoadDF(s\"$tempDir/dataset_1\"))\n",
    "    .join(ParquetToDF.getDF(s\"$xPath/$of/wishlist\").drop(SIMILAR_GROUP_LEVEL), Seq(PRODUCTID), \"outer\")\n",
    "    .join(ParquetToDF.getDF(s\"$xPath/$of/returns\").drop(SIMILAR_GROUP_LEVEL), Seq(PRODUCTID), \"outer\")\n",
    "    .transform(saveNLoadDF(s\"$tempDir/dataset_2\"))\n",
    "    .join(ParquetToDF.getDF(s\"$xPath/$of/users\").drop(SIMILAR_GROUP_LEVEL), Seq(PRODUCTID), \"outer\")\n",
    "    .join(ParquetToDF.getDF(s\"$xPath/$of/availableQuantity\").drop(SIMILAR_GROUP_LEVEL), Seq(PRODUCTID), \"outer\")\n",
    "    .na.fill(0)\n",
    "    \n",
    "    if(of == \"test\"){\n",
    "        var productsToPredict = ParquetToDF.getDF(\"/data/Archive/bhavesh/InventoryPrediction/2023-04-30/PredictionSpace/products\")\n",
    "        xData = productsToPredict.join(xData, Seq(PRODUCTID), \"left\").na.fill(0)\n",
    "    }\n",
    "    \n",
    "    DFToParquet.putDF(s\"$basePath/$of/XData\", xData)\n",
    "    \n",
    "    if(of == \"train\"){\n",
    "        var yData = ParquetToDF.getDF(s\"$yPath/$of/target\").drop(SIMILAR_GROUP_LEVEL)\n",
    "        DFToParquet.putDF(s\"$basePath/$of/YData\", yData)\n",
    "    }\n",
    "    HdfsUtils.delete(tempDir)\n",
    "}\n",
    "CreateDataset(\"train\", datasetDir, datasetDir, s\"$runDir/OriginalDataset\")\n",
    "CreateDataset(\"test\", datasetDir, datasetDir, s\"$runDir/OriginalDataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mgenerateTransformedDataset\u001b[0m: \u001b[1m\u001b[32m(of: String, datasetPath: String, transformedDatasetPath: String, performNormalization: Boolean, isBaselineTransformation: Boolean)Unit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def generateTransformedDataset(of: String, datasetPath: String, transformedDatasetPath: String, performNormalization: Boolean = true, isBaselineTransformation: Boolean = true): Unit = {\n",
    "    var xData: DataFrame = ParquetToDF.getDF(s\"$datasetPath/$of/XData\")\n",
    "    \n",
    "    if(isBaselineTransformation){\n",
    "        xData = (\n",
    "            xData\n",
    "            .select(\"productid\", \"0_sales\", \"1_sales\", \"2_sales\", \"3_sales\", \"4_sales\", \"5_sales\", \"6_sales\", \"7_sales\", \"8_sales\", \"9_sales\", \"10_sales\", \"11_sales\",\n",
    "               \"sales_avg_12_months\", \"sales_std_12_months\", \"0_returns\", \"0_users\", \"0_PLPViewsPerDay\", \"0_PLPClicksPerDay\", \"0_PDPCountPerDay\",\n",
    "               \"0_TotalAddToCartPerDay\", \"0_wishlist\", \"0_totalAvailableQuantity\")\n",
    "            .toDF(\"productid\", \"0_monthSales\", \"1_monthSales\", \"2_monthSales\", \"3_monthSales\", \"4_monthSales\", \"5_monthSales\", \"6_monthSales\", \"7_monthSales\", \"8_monthSales\", \n",
    "              \"9_monthSales\", \"10_monthSales\", \"11_monthSales\", \"avgSales\", \"stddevSales\", \"totalReturn\", \"totalUsers\", \"totalPLPViews\", \"totalPLPClicks\", \n",
    "              \"totalPDPCount\", \"totalATC\", \"totalWishList\", \"totalAvailableQuantity\")\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    \n",
    "    var data: DataFrame = null\n",
    "    if (of == \"train\") {\n",
    "        var yData: DataFrame = ParquetToDF.getDF(s\"$datasetPath/$of/YData\")\n",
    "        data = xData.join(yData, Seq(PRODUCTID))\n",
    "    }\n",
    "    else if(of == \"test\"){\n",
    "        data = xData\n",
    "    }\n",
    "    \n",
    "    val productAttributesLegosFNL: DataFrame = (\n",
    "        ParquetToDF.getDF(s\"$runDir/ProductAttributes\")\n",
    "        .select(PRODUCTID, SIMILAR_GROUP_LEVEL, \"colorfamily\", \"brandname\", \"styletype\", \"pattern\", \"sleeve\", \"pricebucket\")\n",
    "    )\n",
    "    \n",
    "    data = data.join(productAttributesLegosFNL, Seq(PRODUCTID)).na.fill(\"Null\")\n",
    "    \n",
    "    println(data.count)\n",
    "    var attributes = Array(\"colorfamily\", \"pattern\", \"brandname\", \"styletype\", \"sleeve\")\n",
    "    attributes.foreach(\n",
    "        attribute => {\n",
    "            var attrDFMS = CSVToDF.getDF(s\"$runDir/Embeddings/menShirts/${attribute}.csv\", inferSchema=true)\n",
    "            \n",
    "            attrDFMS = attrDFMS\n",
    "            .select(attribute, attrDFMS.columns.filter(_.startsWith(\"normalized\")): _*)\n",
    "            .withColumn(SIMILAR_GROUP_LEVEL, lit(\"830216013\"))\n",
    "            \n",
    "            var attrDFWK = CSVToDF.getDF(s\"$runDir/Embeddings/womenKurtas/${attribute}.csv\", inferSchema=true)\n",
    "            \n",
    "            attrDFWK = attrDFWK\n",
    "            .select(attribute, attrDFMS.columns.filter(_.startsWith(\"normalized\")): _*)\n",
    "            .withColumn(SIMILAR_GROUP_LEVEL, lit(\"830303011\"))\n",
    "            \n",
    "            var cols = attrDFWK.columns\n",
    "            \n",
    "            var attrDF = attrDFMS.select(cols.head, cols.tail: _*).union(attrDFWK)\n",
    "            \n",
    "            data = data.join(attrDF, Seq(SIMILAR_GROUP_LEVEL, attribute)).drop(attribute)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    println(data.count)\n",
    "    val menShirtsData: DataFrame = data.filter(col(SIMILAR_GROUP_LEVEL) === \"830216013\")\n",
    "    val womenKurtasData: DataFrame = data.filter(col(SIMILAR_GROUP_LEVEL) === \"830303011\")\n",
    "    \n",
    "    DFToParquet.putDF(s\"$transformedDatasetPath/combined/data/$of\", data)\n",
    "    DFToParquet.putDF(s\"$transformedDatasetPath/menShirts/data/$of\", menShirtsData)\n",
    "    DFToParquet.putDF(s\"$transformedDatasetPath/womenKurtas/data/$of\", womenKurtasData)\n",
    "    \n",
    "    if (performNormalization){\n",
    "        \n",
    "        var colsToScale: Array[String] = Array(\n",
    "            \"0_monthSales\", \"1_monthSales\", \"2_monthSales\", \"3_monthSales\", \"4_monthSales\", \"5_monthSales\", \"6_monthSales\", \"7_monthSales\", \n",
    "            \"8_monthSales\", \"9_monthSales\", \"10_monthSales\", \"11_monthSales\", \"avgSales\", \"stddevSales\", \"totalReturn\", \"totalUsers\", \n",
    "            \"totalPLPViews\", \"totalPLPClicks\", \"totalPDPCount\", \"totalATC\", \"totalWishList\", \"totalAvailableQuantity\", \"pricebucket\")\n",
    "\n",
    "        if(of == \"train\"){\n",
    "\n",
    "            colsToScale = colsToScale ++ Array(\"yQuantity\")\n",
    "        }\n",
    "\n",
    "        DFToParquet.putDF(s\"$transformedDatasetPath/combined/normalizedData/$of\", data.transform(minMaxScaler(colsToScale)))\n",
    "        DFToParquet.putDF(s\"$transformedDatasetPath/menShirts/normalizedData/$of\", menShirtsData.transform(minMaxScaler(colsToScale)))\n",
    "        DFToParquet.putDF(s\"$transformedDatasetPath/womenKurtas/normalizedData/$of\", womenKurtasData.transform(minMaxScaler(colsToScale)))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generateTransformedDataset(\"train\", s\"$runDir/OriginalDataset\", s\"$runDir/TransformedDataset/baseline\", true, true)\n",
    "generateTransformedDataset(\"test\", s\"$runDir/OriginalDataset\", s\"$runDir/TransformedDataset/baseline\", true, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generateTransformedDataset(\"train\", s\"$runDir/OriginalDataset\", s\"$runDir/TransformedDataset/complete\", false, false)\n",
    "generateTransformedDataset(\"test\", s\"$runDir/OriginalDataset\", s\"$runDir/TransformedDataset/complete\", false, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mres31\u001b[0m: \u001b[1m\u001b[32mLong\u001b[0m = 157640\n"
     ]
    }
   ],
   "source": [
    "productsToPredict.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productAttrs: org.apache.spark.sql.DataFrame = [productid: string, similargrouplevel: string ... 5 more fields]\n",
      "root\n",
      " |-- productid: string (nullable = true)\n",
      " |-- similargrouplevel: string (nullable = true)\n",
      " |-- colorfamily: string (nullable = true)\n",
      " |-- brandname: string (nullable = true)\n",
      " |-- sleeve: string (nullable = true)\n",
      " |-- pattern: string (nullable = true)\n",
      " |-- styletype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "productAttrs = productAttrs.select(\"productid\", \"similargrouplevel\", \"colorfamily\", \"brandname\", \"sleeve\", \"pattern\", \"styletype\")\n",
    "productAttrs.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productsToPredict: org.apache.spark.sql.DataFrame = [productid: string, similargrouplevel: string ... 5 more fields]\n",
      "root\n",
      " |-- productid: string (nullable = false)\n",
      " |-- similargrouplevel: string (nullable = false)\n",
      " |-- colorfamily: string (nullable = false)\n",
      " |-- brandname: string (nullable = false)\n",
      " |-- sleeve: string (nullable = false)\n",
      " |-- pattern: string (nullable = false)\n",
      " |-- styletype: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "productsToPredict = productsToPredict.join(productAttrs, Seq(PRODUCTID)).na.fill(\"Null\")\n",
    "productsToPredict.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mres37\u001b[0m: \u001b[1m\u001b[32mLong\u001b[0m = 157640\n"
     ]
    }
   ],
   "source": [
    "productsToPredict.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mattribute\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = sleeve\n",
      "\u001b[1m\u001b[34mattrDFMS\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [sleeve_0: double, sleeve_1: double ... 4 more fields]\n",
      "attrDFMS: org.apache.spark.sql.DataFrame = [sleeve: string, normalized_sleeve_0: double ... 2 more fields]\n",
      "\u001b[1m\u001b[34mattrDFWK\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [sleeve_0: double, sleeve_1: double ... 4 more fields]\n",
      "attrDFWK: org.apache.spark.sql.DataFrame = [sleeve: string, normalized_sleeve_0: double ... 2 more fields]\n",
      "\u001b[1m\u001b[34mcols\u001b[0m: \u001b[1m\u001b[32mArray[String]\u001b[0m = Array(sleeve, normalized_sleeve_0, normalized_sleeve_1, similargrouplevel)\n",
      "\u001b[1m\u001b[34mattrDF\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m = [sleeve: string, normalized_sleeve_0: double ... 2 more fields]\n"
     ]
    }
   ],
   "source": [
    "var attribute = \"sleeve\"\n",
    "var attrDFMS = CSVToDF.getDF(s\"$runDir/Embeddings/menShirts/${attribute}.csv\", inferSchema=true)\n",
    "            \n",
    "attrDFMS = (attrDFMS\n",
    ".select(attribute, attrDFMS.columns.filter(_.startsWith(\"normalized\")): _*)\n",
    ".withColumn(SIMILAR_GROUP_LEVEL, lit(\"830216013\")))\n",
    "\n",
    "var attrDFWK = CSVToDF.getDF(s\"$runDir/Embeddings/womenKurtas/${attribute}.csv\", inferSchema=true)\n",
    "\n",
    "attrDFWK = (attrDFWK\n",
    ".select(attribute, attrDFMS.columns.filter(_.startsWith(\"normalized\")): _*)\n",
    ".withColumn(SIMILAR_GROUP_LEVEL, lit(\"830303011\")))\n",
    "\n",
    "var cols = attrDFWK.columns\n",
    "\n",
    "var attrDF = attrDFMS.select(cols.head, cols.tail: _*).union(attrDFWK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+------------------+-----------+---------+-----------+---------+\n",
      "|similargrouplevel|sleeve          |productid         |colorfamily|brandname|pattern    |styletype|\n",
      "+-----------------+----------------+------------------+-----------+---------+-----------+---------+\n",
      "|830303011        |stylised sleeve |460208940_offwhite|white      |ajio     |solid      |straight |\n",
      "|830303011        |stylised sleeve |440780256_red     |red        |avaasa   |solid      |a-line   |\n",
      "|830303011        |stylised sleeve |460528805_yellow  |yellow     |indya    |indian     |a-line   |\n",
      "|830303011        |racerback sleeve|460863887_beige   |beige      |svrnaa   |floral     |a-line   |\n",
      "|830303011        |stylised sleeve |440932774_navy    |blue       |avaasa   |floral     |flared   |\n",
      "|830303011        |stylised sleeve |440773531_blue    |blue       |w        |solid      |straight |\n",
      "|830303011        |stylised sleeve |440875319_pink    |pink       |w        |embellished|straight |\n",
      "|830303011        |racerback sleeve|460863887_maroon  |maroon     |svrnaa   |floral     |a-line   |\n",
      "|830303011        |stylised sleeve |440772937_black   |black      |aurelia  |Null       |straight |\n",
      "+-----------------+----------------+------------------+-----------+---------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "productsToPredict.join(attrDF, Seq(SIMILAR_GROUP_LEVEL, attribute), \"leftanti\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [productid: string, 0_sales: double ... 155 more fields]\n",
      "+------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+------------------+------------------+-------------------+-------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+-----------------+------------------+-----------------+-----------------------+-----------------+------------------+-----------------+-----------------------+---------------------------+----------------------------+---------------------------+---------------------------------+---------------------------+----------------------------+---------------------------+---------------------------------+----------------------------+----------------------------+-----------------------------+-----------------------------+----------------------------+----------------------------+----------------------------------+----------------------------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------------------+---------------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+----------+--------------------+--------------------+---------------------+---------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+------------------+------------------+-------------------+-------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+-------------------------+-----------------------+-------------------------+-----------------------+-----------------------------------+---------------------------------+-----------------------------------+---------------------------------+------------------------------------+------------------------------------+----------------------------------+----------------------------------+\n",
      "|productid         |0_sales|1_sales|2_sales|3_sales|4_sales|5_sales|6_sales|7_sales|8_sales|9_sales|10_sales|11_sales|sales_avg_3_months|sales_avg_6_months|sales_avg_12_months|sales_std_12_months|0_PLPViewsPerDay|0_PLPClicksPerDay|0_PDPCountPerDay|0_TotalAddToCartPerDay|1_PLPViewsPerDay|1_PLPClicksPerDay|1_PDPCountPerDay|1_TotalAddToCartPerDay|2_PLPViewsPerDay|2_PLPClicksPerDay|2_PDPCountPerDay|2_TotalAddToCartPerDay|3_PLPViewsPerDay|3_PLPClicksPerDay|3_PDPCountPerDay|3_TotalAddToCartPerDay|4_PLPViewsPerDay|4_PLPClicksPerDay|4_PDPCountPerDay|4_TotalAddToCartPerDay|5_PLPViewsPerDay|5_PLPClicksPerDay|5_PDPCountPerDay|5_TotalAddToCartPerDay|6_PLPViewsPerDay|6_PLPClicksPerDay|6_PDPCountPerDay|6_TotalAddToCartPerDay|7_PLPViewsPerDay|7_PLPClicksPerDay|7_PDPCountPerDay|7_TotalAddToCartPerDay|8_PLPViewsPerDay|8_PLPClicksPerDay|8_PDPCountPerDay|8_TotalAddToCartPerDay|9_PLPViewsPerDay|9_PLPClicksPerDay|9_PDPCountPerDay|9_TotalAddToCartPerDay|10_PLPViewsPerDay|10_PLPClicksPerDay|10_PDPCountPerDay|10_TotalAddToCartPerDay|11_PLPViewsPerDay|11_PLPClicksPerDay|11_PDPCountPerDay|11_TotalAddToCartPerDay|PLPViewsPerDay_avg_3_months|PLPClicksPerDay_avg_3_months|PDPCountPerDay_avg_3_months|TotalAddToCartPerDay_avg_3_months|PLPViewsPerDay_avg_6_months|PLPClicksPerDay_avg_6_months|PDPCountPerDay_avg_6_months|TotalAddToCartPerDay_avg_6_months|PLPViewsPerDay_avg_12_months|PLPViewsPerDay_std_12_months|PLPClicksPerDay_avg_12_months|PLPClicksPerDay_std_12_months|PDPCountPerDay_avg_12_months|PDPCountPerDay_std_12_months|TotalAddToCartPerDay_avg_12_months|TotalAddToCartPerDay_std_12_months|0_wishlist|1_wishlist|2_wishlist|3_wishlist|4_wishlist|5_wishlist|6_wishlist|7_wishlist|8_wishlist|9_wishlist|wishlist_avg_3_months|wishlist_avg_6_months|0_returns|1_returns|2_returns|3_returns|4_returns|5_returns|6_returns|7_returns|8_returns|9_returns|10_returns|11_returns|returns_avg_3_months|returns_avg_6_months|returns_avg_12_months|returns_std_12_months|0_users|1_users|2_users|3_users|4_users|5_users|6_users|7_users|8_users|9_users|10_users|11_users|users_avg_3_months|users_avg_6_months|users_avg_12_months|users_std_12_months|0_totalAvailableQuantity|0_maxAvailableQuantity|1_totalAvailableQuantity|1_maxAvailableQuantity|2_totalAvailableQuantity|2_maxAvailableQuantity|3_totalAvailableQuantity|3_maxAvailableQuantity|4_totalAvailableQuantity|4_maxAvailableQuantity|5_totalAvailableQuantity|5_maxAvailableQuantity|6_totalAvailableQuantity|6_maxAvailableQuantity|7_totalAvailableQuantity|7_maxAvailableQuantity|8_totalAvailableQuantity|8_maxAvailableQuantity|9_totalAvailableQuantity|9_maxAvailableQuantity|10_totalAvailableQuantity|10_maxAvailableQuantity|11_totalAvailableQuantity|11_maxAvailableQuantity|totalAvailableQuantity_avg_3_months|maxAvailableQuantity_avg_3_months|totalAvailableQuantity_avg_6_months|maxAvailableQuantity_avg_6_months|totalAvailableQuantity_avg_12_months|totalAvailableQuantity_std_12_months|maxAvailableQuantity_avg_12_months|maxAvailableQuantity_std_12_months|\n",
      "+------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+------------------+------------------+-------------------+-------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+-----------------+------------------+-----------------+-----------------------+-----------------+------------------+-----------------+-----------------------+---------------------------+----------------------------+---------------------------+---------------------------------+---------------------------+----------------------------+---------------------------+---------------------------------+----------------------------+----------------------------+-----------------------------+-----------------------------+----------------------------+----------------------------+----------------------------------+----------------------------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------------------+---------------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+----------+--------------------+--------------------+---------------------+---------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+------------------+------------------+-------------------+-------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+-------------------------+-----------------------+-------------------------+-----------------------+-----------------------------------+---------------------------------+-----------------------------------+---------------------------------+------------------------------------+------------------------------------+----------------------------------+----------------------------------+\n",
      "|440780256_red     |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |1.0    |1.0     |0.0     |0.0               |0.0               |0.16666666666666666|0.38924947208076155|0.0             |0.0              |0.0             |0.0                   |0.0             |0.0              |0.0             |0.0                   |0.0             |0.0              |0.0             |0.0                   |0.0             |0.0              |2.0             |0.0                   |0.0             |0.0              |0.0             |0.0                   |0.0             |1.0              |0.0             |0.0                   |0.0             |1.0              |2.0             |0.0                   |0.0             |0.0              |1.0             |0.0                   |0.0             |0.0              |0.0             |0.0                   |3443.0          |164.0            |370.0           |6.0                   |821.0            |43.0              |60.0             |2.0                    |0.0              |0.0               |0.0              |0.0                    |0.0                        |0.0                         |0.0                        |0.0                              |0.0                        |0.16666666666666666         |0.3333333333333333         |0.0                              |355.3333333333333           |1000.5974881706096          |17.416666666666668           |47.77496174458929            |36.25                       |106.48954280713542          |0.6666666666666666                |1.775250729197189                 |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0                  |0.0                  |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |1.0       |0.0       |0.0                 |0.0                 |0.08333333333333333  |0.28867513459481287  |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |1.0    |1.0     |0.0     |0.0               |0.0               |0.16666666666666666|0.38924947208076155|0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                      |0                      |0.0                      |0                      |0.0                                |0.0                              |0.0                                |0.0                              |0.0                                 |0.0                                 |0.0                               |0.0                               |\n",
      "|460208940_offwhite|0.0    |2.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0     |0.0     |0.6666666666666666|0.3333333333333333|0.16666666666666666|0.5773502691896256 |22.0            |1.0              |1.0             |0.0                   |909.0           |126.0            |186.0           |2.0                   |562.0           |69.0             |62.0            |1.0                   |0.0             |0.0              |0.0             |0.0                   |4.0             |2.0              |1.0             |0.0                   |1.0             |1.0              |2.0             |0.0                   |0.0             |0.0              |0.0             |0.0                   |1.0             |0.0              |0.0             |0.0                   |1.0             |0.0              |0.0             |0.0                   |0.0             |0.0              |2.0             |0.0                   |0.0              |0.0               |0.0              |0.0                    |0.0              |0.0               |0.0              |0.0                    |497.6666666666667          |65.33333333333333           |83.0                       |1.0                              |249.66666666666666         |33.166666666666664          |42.0                       |0.5                              |125.0                       |294.66899765977786          |16.583333333333332           |39.70678516171749            |21.166666666666668          |54.83335635994727           |0.25                              |0.621581560508061                 |0.0       |20.0      |6.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |0.0       |8.666666666666666    |4.333333333333333    |0.0      |1.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0      |0.0       |0.0       |0.3333333333333333  |0.16666666666666666 |0.08333333333333333  |0.2886751345948128   |0.0    |2.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0     |0.0     |0.6666666666666666|0.3333333333333333|0.16666666666666666|0.5773502691896256 |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                     |0                     |0.0                      |0                      |0.0                      |0                      |0.0                                |0.0                              |0.0                                |0.0                              |0.0                                 |0.0                                 |0.0                               |0.0                               |\n",
      "+------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+------------------+------------------+-------------------+-------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+----------------+-----------------+----------------+----------------------+-----------------+------------------+-----------------+-----------------------+-----------------+------------------+-----------------+-----------------------+---------------------------+----------------------------+---------------------------+---------------------------------+---------------------------+----------------------------+---------------------------+---------------------------------+----------------------------+----------------------------+-----------------------------+-----------------------------+----------------------------+----------------------------+----------------------------------+----------------------------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------------------+---------------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+----------+--------------------+--------------------+---------------------+---------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+------------------+------------------+-------------------+-------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+------------------------+----------------------+-------------------------+-----------------------+-------------------------+-----------------------+-----------------------------------+---------------------------------+-----------------------------------+---------------------------------+------------------------------------+------------------------------------+----------------------------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var df = ParquetToDF.getDF(s\"$runDir/OriginalDataset/test/XData\")\n",
    "df.filter(col(\"productid\").isin(\"460208940_offwhite\", \"440780256_red\")).show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intergration Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34msuffix\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 2023-04-30/queryProductMap_colorfamily_pricebucket_styletype_pattern_sleeve_brandname\n",
      "\u001b[1m\u001b[34msuffix2\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = colorfamily_pricebucket_styletype_pattern_sleeve_brandname\n",
      "\u001b[1m\u001b[34mproductAttr\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [productid: string, similargrouplevel: string ... 8 more fields]\n",
      "productAttr: org.apache.spark.sql.DataFrame = [productid: string, similargrouplevel: string ... 9 more fields]\n",
      "\u001b[1m\u001b[34mqueriesDF\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [query: string, productid: string ... 2 more fields]\n",
      "\u001b[1m\u001b[34mnewQueryMap\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [query: string, template: string ... 2 more fields]\n",
      "queriesDF: org.apache.spark.sql.DataFrame = [oldQuery: string, template: string ... 3 more fields]\n"
     ]
    }
   ],
   "source": [
    "var suffix = \"2023-04-30/queryProductMap_colorfamily_pricebucket_styletype_pattern_sleeve_brandname\"\n",
    "var suffix2 = \"colorfamily_pricebucket_styletype_pattern_sleeve_brandname\"\n",
    "\n",
    "var productAttr = spark.read.parquet(\"/data/Archive/inventory/\"+suffix+\"/processedProductAttr\").select(col(\"productid\") as \"productid\",col(\"similargrouplevel\"),col(\"colorfamily\"),col(\"brandname\"),col(\"styletype\"),col(\"pattern\"),col(\"sleeve\").as(\"sleeve\"),col(\"WeightedAvgPrice\").as(\"price\"),col(\"title\"),col(\"imgcode\"))\n",
    "\n",
    "productAttr = productAttr.withColumn(\"category_name\",when(col(\"similargrouplevel\")===\"830216013\",lit(\"Men-Shirts\")).when(col(\"similargrouplevel\")===\"830303011\",lit(\"Women-Kurtas\")))\n",
    "\n",
    "var queriesDF = spark.read.parquet(s\"/data/Archive/bhavesh/InventoryPrediction/2023-04-30/QueryProductMapping/suffix=$suffix2\")\n",
    "\n",
    "var newQueryMap = spark.read.parquet(\"/data/Archive/inventory/2023-04-30/queryProductMap_colorfamily_pricebucket_styletype_pattern_sleeve_brandname/attributesQueryInfo/final\").select(\"query\",\"template\",\"similargrouplevel\",\"newQuery\")\n",
    "\n",
    "queriesDF = queriesDF.join(newQueryMap,Seq(\"query\",\"template\",\"similargrouplevel\")).withColumnRenamed(\"query\",\"oldQuery\").withColumnRenamed(\"newQuery\",\"query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mpredictedqueries\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m = [similargrouplevel: string, query: string]\n",
      "\u001b[1m\u001b[34mrequiredProducts\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m = [productid: string]\n"
     ]
    }
   ],
   "source": [
    "var predictedqueries = spark.read.parquet(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/predictions\").select(\"similargrouplevel\",\"query\").distinct\n",
    "\n",
    "var requiredProducts = queriesDF.join(predictedqueries,Seq(\"similargrouplevel\",\"query\")).select(\"productid\").distinct\n",
    "\n",
    "productAttr.join(requiredProducts,Seq(\"productid\")).write.mode(\"overwrite\").parquet(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/productDetails\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mres35\u001b[0m: \u001b[1m\u001b[32mLong\u001b[0m = 434089\n"
     ]
    }
   ],
   "source": [
    "requiredProducts.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mqueryMonthly\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [oldQuery: string, template: string ... 5 more fields]\n"
     ]
    }
   ],
   "source": [
    "var queryMonthly =  (\n",
    "    spark.read.parquet(\"/data/Archive/bhavesh/InventoryPrediction/2023-04-30/MonthlyQuantity/query\")\n",
    "    .withColumnRenamed(\"monthsInHis\",\"pastmonth\").filter(col(\"pastmonth\")>0)\n",
    "    .join(newQueryMap,Seq(\"query\",\"template\",\"similargrouplevel\"))\n",
    "    .withColumnRenamed(\"query\",\"oldQuery\")\n",
    "    .withColumnRenamed(\"newQuery\",\"query\")\n",
    ")\n",
    "(\n",
    "    queryMonthly\n",
    "    .withColumn(\"category_name\",when(col(\"similargrouplevel\")===\"830216013\",lit(\"Men-Shirts\"))\n",
    "                .when(col(\"similargrouplevel\")===\"830303011\",lit(\"Women-Kurtas\")))\n",
    "    .join(predictedqueries,Seq(\"query\",\"similargrouplevel\"))\n",
    "    .write.mode(\"overwrite\")\n",
    "    .parquet(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/monthlySales\")  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [itemid: string, inferred_vector: array<double>]\n",
      "root\n",
      " |-- itemid: string (nullable = true)\n",
      " |-- inferred_vector: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "\u001b[1m\u001b[34mprodDetails\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [itemid: string, similargrouplevel: string]\n",
      "root\n",
      " |-- itemid: string (nullable = true)\n",
      " |-- similargrouplevel: string (nullable = true)\n",
      "\n",
      "df: org.apache.spark.sql.DataFrame = [itemid: string, inferred_vector: array<double> ... 1 more field]\n",
      "df: org.apache.spark.sql.DataFrame = [itemid: string, inferred_vector: array<double> ... 2 more fields]\n",
      "root\n",
      " |-- itemid: string (nullable = true)\n",
      " |-- inferred_vector: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- similargrouplevel: string (nullable = true)\n",
      " |-- livestatus: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var df = ParquetToDF.getDF(\"/data/ecomm/ajio/metadata/styleVectorsViT_large\")\n",
    "df.printSchema\n",
    "\n",
    "var prodDetails = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/productDetails\").select(col(PRODUCTID).as(\"itemid\"), col(\"similargrouplevel\"))\n",
    "prodDetails.printSchema\n",
    "\n",
    "df = df.join(prodDetails, Seq(\"itemid\"))\n",
    "df = df.withColumn(\"livestatus\", lit(1))\n",
    "df.printSchema\n",
    "DFToParquet.putDF(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/productImageEmbeddings\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mproductDetails\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [productid: string, similargrouplevel: string ... 9 more fields]\n",
      "root\n",
      " |-- productid: string (nullable = true)\n",
      " |-- similargrouplevel: string (nullable = true)\n",
      " |-- colorfamily: string (nullable = true)\n",
      " |-- brandname: string (nullable = true)\n",
      " |-- styletype: string (nullable = true)\n",
      " |-- pattern: string (nullable = true)\n",
      " |-- sleeve: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- imgcode: string (nullable = true)\n",
      " |-- category_name: string (nullable = true)\n",
      "\n",
      "434089\n"
     ]
    }
   ],
   "source": [
    "var productDetails = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/productDetails\")\n",
    "productDetails.printSchema\n",
    "println(productDetails.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mqueryMonthly\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [query: string, similargrouplevel: int ... 6 more fields]\n",
      "root\n",
      " |-- query: string (nullable = true)\n",
      " |-- similargrouplevel: integer (nullable = true)\n",
      " |-- oldQuery: string (nullable = true)\n",
      " |-- template: string (nullable = true)\n",
      " |-- pastmonth: integer (nullable = true)\n",
      " |-- quantity: double (nullable = true)\n",
      " |-- tempDateForTimeSeries: date (nullable = true)\n",
      " |-- category_name: string (nullable = true)\n",
      "\n",
      "5497095\n"
     ]
    }
   ],
   "source": [
    "var queryMonthly = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/monthlySales\")\n",
    "queryMonthly.printSchema\n",
    "println(queryMonthly.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+-----------------+-------------------------------------------------+---------------------------------------------------+---------+--------+---------------------+-------------+\n",
      "|query                                              |similargrouplevel|oldQuery                                         |template                                           |pastmonth|quantity|tempDateForTimeSeries|category_name|\n",
      "+---------------------------------------------------+-----------------+-------------------------------------------------+---------------------------------------------------+---------+--------+---------------------+-------------+\n",
      "|cool-colors_green_check_2_#_classic                |830216013        |check_2_green_classic_cool-colors                |pattern_pricebucket_colorfamily_styletype_brandname|2        |2.0     |2023-03-01           |Men-Shirts   |\n",
      "|soch_#_indian_3_#_#                                |830303011        |indian_3_soch                                    |pattern_pricebucket_brandname                      |12       |52.0    |2022-05-01           |Women-Kurtas |\n",
      "|indo-era_blue_stripes_#_3-4th sleeve_straight      |830303011        |stripes_3-4th sleeve_blue_straight_indo-era      |pattern_sleeve_colorfamily_styletype_brandname     |7        |2.0     |2022-10-01           |Women-Kurtas |\n",
      "|jack-jones_green_check_#_full-length sleeve_classic|830216013        |check_full-length sleeve_green_classic_jack-jones|pattern_sleeve_colorfamily_styletype_brandname     |1        |44.0    |2023-04-01           |Men-Shirts   |\n",
      "|indian-terrain_pink_micro-print_2_#_classic        |830216013        |micro-print_2_pink_classic_indian-terrain        |pattern_pricebucket_colorfamily_styletype_brandname|4        |31.0    |2023-01-01           |Men-Shirts   |\n",
      "+---------------------------------------------------+-----------------+-------------------------------------------------+---------------------------------------------------+---------+--------+---------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queryMonthly.show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mpredictions\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [similargrouplevel: string, category_name: string ... 7 more fields]\n",
      "root\n",
      " |-- similargrouplevel: string (nullable = true)\n",
      " |-- category_name: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- m1: double (nullable = true)\n",
      " |-- m2: double (nullable = true)\n",
      " |-- m3: double (nullable = true)\n",
      " |-- m4: double (nullable = true)\n",
      " |-- m5: double (nullable = true)\n",
      " |-- m6: double (nullable = true)\n",
      "\n",
      "765221\n"
     ]
    }
   ],
   "source": [
    "var predictions = ParquetToDF.getDF(\"/data/ecomm/ajio/processed/inventory/integrationSimulator/predictions\")\n",
    "predictions.printSchema\n",
    "println(predictions.count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
